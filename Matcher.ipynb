{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import io\n",
    "import requests\n",
    "\n",
    "import time\n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "scope = \"https://spreadsheets.google.com/feeds\"\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(\"matcher-272116-8801bce55bcb.json\", scope)\n",
    "gs = gspread.authorize(credentials)\n",
    "\n",
    "data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Journey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No journeys available\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.anyvan.com/board/cyfe/express_interest_expresses\"\n",
    "s = requests.get(url).content\n",
    "\n",
    "try :\n",
    "    data = pd.read_csv(io.StringIO(s.decode(\"utf-8\"))).sort_values(by = [\"start_end\"], ascending = False)\n",
    "except :\n",
    "    print(\"No journeys available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/1o7jEklbPYk-7So0UALnt8dZCYlIbdyXhzsgm9MHf82I/edit#gid=0\"\n",
    "\n",
    "express_guaranteed_sheet = gs.open_by_url(url).worksheet(\"journeys\").get_all_values()\n",
    "data = pd.DataFrame(express_guaranteed_sheet[1:], columns = express_guaranteed_sheet[0])\n",
    "data = data.replace(\"\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/1_syJVv1Uni8oSa9BhtAjVcl2EZYZmJn03VKg9vofcD4/edit#gid=0\"\n",
    "\n",
    "return_journey_converter_sheet = gs.open_by_url(url).worksheet(\"Input\").get_all_values()[15:]\n",
    "returns = pd.DataFrame(return_journey_converter_sheet[1:], columns = return_journey_converter_sheet[0])\n",
    "returns = returns.drop(columns = returns.columns[16:])\n",
    "returns[\"nickname\"].replace(\"\", float(\"NaN\"), inplace = True)\n",
    "returns = returns.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = {\"Luton Van\" : 20, \n",
    "         \"LWB up to 4m\" : 10.5,\n",
    "         \"MWB up to 3m\" : 7.5,\n",
    "         \"Not applicable\" : 12,\n",
    "         \"XLWB up 4m+\" : 14.5,\n",
    "         \"SWB up to 2.4m\" : 5.5,\n",
    "         \"Small Van\" : 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/1t0L9sgsUt-BT7wJWBNZ4fNY-Bo5GNytXP1wmkejFVw0/edit#gid=1205069010\"\n",
    "\n",
    "TP_log_providers_sheet = gs.open_by_url(url).worksheet(\"format2\").get_all_values()[7:]\n",
    "TP_log_providers = pd.DataFrame(TP_log_providers_sheet[1:], columns = TP_log_providers_sheet[0])\n",
    "providers = TP_log_providers.where(np.logical_and(TP_log_providers[\"vehicle\"] != \"N/A\", np.logical_and(TP_log_providers[\"TP & REG\"] != \"AVStore #YN19FHD\", np.logical_and(TP_log_providers[\"TP & REG\"] != \"1London #YN19FHF\", TP_log_providers[\"TP & REG\"] != \"DWB91 #YN19FHD\")))).dropna(how = \"all\").reset_index(drop = True).drop(columns = TP_log_providers.columns[-1])\n",
    "date = providers.columns[-1]\n",
    "\n",
    "providers[\"Size\"] = [sizes[vehicle] for vehicle in providers[\"vehicle\"]]\n",
    "providers[\"National?\"] = [int(math.ceil(55 + (100 - float(nuts2c)) / 2 + (2000 if code.endswith(\"N\") else 0))) for nuts2c,code in zip(providers[\"nuts2c\"], providers[date])]\n",
    "providers[\"1Man\"] = [1 if (code.startswith(\"1\") or code.startswith(\"O\")) else 0 for code in providers[date]]\n",
    "providers[\"2Man\"] = [2 if (code.startswith(\"2\") or code.startswith(\"O\")) else 0 for code in providers[date]]\n",
    "providers[\"returns\"] = [1 if TP in returns[\"name#reg\"] else 0 for TP in providers[\"TP & REG\"]]\n",
    "providers[\"guaranteed\"] = [1 if isreturn == 1 else -1 for isreturn in providers[\"returns\"]]\n",
    "providers[\"special code\"] = [\"2man-TL-LDN-cc\" if (TwoMan == 2 and TL == \"1\") else \"TL-LDN-cc\" if (TL == \"1\") else \"2man-LDN-cc\" if (TwoMan == 2) else \"LDN-cc\" for TwoMan,TL in zip(providers[\"2Man\"], providers[\"TL\"])]\n",
    "providers[\"capacity\"] = [16 if size >= 16 else size for size in providers[\"Size\"]]\n",
    "\n",
    "providers = providers.sort_values(by = [\"TP & REG\"]).reset_index(drop = True)\n",
    "providers[\"index\"] = providers.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expressing TPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"TP\", \"lat\", \"lng\", \"expressions\", \"guaranteed\", \"boooked\"]\n",
    "expressing_TPs = pd.DataFrame(columns = columns)\n",
    "\n",
    "if data is not None :\n",
    "    for TP in data[\"name#reg\"].dropna().unique() :\n",
    "        data_TP = data.where(data[\"name#reg\"] == TP).dropna(how = \"all\")\n",
    "        lat = round(float(data_TP.iloc[0][\"veh_lat\"]), 2)\n",
    "        lng = round(float(data_TP.iloc[0][\"veh_lng\"]), 2)\n",
    "        expressions = len(data_TP.index)\n",
    "        guaranteed = 1 if (TP in providers[\"TP & REG\"] or TP in returns[\"name#reg\"]) else 0\n",
    "        booked = 1 if TP in returns[\"name#reg\"] else 0\n",
    "        expressing_TPs = expressing_TPs.append(pd.DataFrame([[TP, lat, lng, expressions, guaranteed, booked]], columns = columns))\n",
    "else :\n",
    "    print(\"No journeys available\")\n",
    "    \n",
    "expressing_TPs = expressing_TPs.sort_values(by = [\"TP\"]).reset_index(drop = True)\n",
    "expressing_TPs[\"index\"] = expressing_TPs.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_namereg = np.append(providers[\"TP & REG\"], expressing_TPs[\"TP\"])\n",
    "TP_lat = np.append(providers[\"Lat\"], expressing_TPs[\"lat\"])\n",
    "TP_lng = np.append(providers[\"Lng\"], expressing_TPs[\"lng\"])\n",
    "TP_TL = np.append(providers[\"TL\"], np.full(len(expressing_TPs.index), np.nan))\n",
    "TP_capacity = np.append(providers[\"Size\"], np.full(len(expressing_TPs.index), np.nan))\n",
    "TP_maxkm = np.append(providers[\"National?\"], np.full(len(expressing_TPs.index), np.nan))\n",
    "TP_1man = np.append(providers[\"1Man\"], np.full(len(expressing_TPs.index), np.nan))\n",
    "TP_2man = np.append(providers[\"2Man\"], np.full(len(expressing_TPs.index), np.nan))\n",
    "TP_guaranteed = np.append(providers[\"guaranteed\"], expressing_TPs[\"guaranteed\"])\n",
    "TP_provider = np.append(np.ones(len(providers.index), dtype = bool), np.zeros(len(expressing_TPs.index), dtype = bool))\n",
    "\n",
    "columns = [\"TP\", \"lat\", \"lng\", \"TL\", \"capacity\", \"maxkm\", \"1man\", \"2man\", \"guaranteed\", \"provider\"]\n",
    "TPs = pd.DataFrame(zip(TP_namereg, TP_lat, TP_lng, TP_TL, TP_capacity, TP_maxkm, TP_1man, TP_2man, TP_guaranteed, TP_provider), columns = columns)\n",
    "TPs = TPs.where(TPs[\"guaranteed\"] <= 0).dropna(how = \"all\").sort_values(by = [\"provider\", \"TP\"], ascending = [False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate iarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_funct(start_lat, start_lng, lat, lng) :\n",
    "    return 2 * 6371 * np.arcsin(np.sqrt(np.sin((start_lat - lat) * np.pi / 360) ** 2 \n",
    "                                           + np.cos(start_lat * np.pi / 180) \n",
    "                                           * np.cos(lat * np.pi / 180) \n",
    "                                           * np.sin((start_lng - lng) * np.pi / 360) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 1.930 secs to run\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if data is not None :\n",
    "    journeys = data[\"journey_id\"].unique()\n",
    "    iarray = np.zeros((len(TPs.index), len(journeys)), dtype = float)\n",
    "\n",
    "    for i in range(len(journeys)) :\n",
    "        journey = data.where(data[\"journey_id\"] == journeys[i]).dropna(how = \"all\")\n",
    "        \n",
    "        for j in range(len(TPs.index)) :\n",
    "            if int(TPs[\"guaranteed\"].iloc[j]) == -1 :\n",
    "                if TPs[\"TP\"].iloc[j] in journey[\"name#reg\"].values :\n",
    "                    journey_subset = journey.where(journey[\"name#reg\"] == TPs[\"TP\"].iloc[j]).dropna(how = \"all\").iloc[0]\n",
    "                    if float(journey_subset[\"min_dist\"]) >= 5 :\n",
    "                        iarray[j, i] = 5\n",
    "                    else :\n",
    "                        iarray[j, i] = float(journey_subset[\"min_dist\"])\n",
    "                else :\n",
    "                    if float(journey[\"max_m3\"].iloc[0]) <= float(TPs[\"capacity\"].iloc[j]) :\n",
    "                        if float(journey[\"start_end\"].iloc[0]) <= float(TPs[\"maxkm\"].iloc[j]) :\n",
    "                            if int(journey[\"number_of_men\"].iloc[0]) == int(TPs[\"1man\"].iloc[j]) or int(journey[\"number_of_men\"].iloc[0]) == int(TPs[\"2man\"].iloc[j]) :\n",
    "                                if int(journey[\"tail_lift\"].iloc[0]) <= int(TPs[\"TL\"].iloc[j]) :\n",
    "                                    distance = distance_funct(float(journey[\"start_lat\"].iloc[0]), float(journey[\"start_lng\"].iloc[0]), float(TPs[\"lat\"].iloc[j]), float(TPs[\"lng\"].iloc[j]))\n",
    "                                    if distance <= (float(TPs[\"maxkm\"].iloc[j]) if float(TPs[\"maxkm\"].iloc[j]) < 2000 else float(TPs[\"maxkm\"].iloc[j]) - 2000) :\n",
    "                                        iarray[j, i] = distance\n",
    "            elif TPs[\"TP\"].iloc[j] in journey[\"name#reg\"].values :\n",
    "                iarray[j, i] = float(journey.where(journey[\"name#reg\"] == TPs[\"TP\"].iloc[j]).dropna(how = \"all\")[\"min_dist\"].iloc[0])\n",
    "else :\n",
    "    print(\"No journeys available\")\n",
    "                \n",
    "print(\"Took {0:.3f} secs to run\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
