{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import io\n",
    "import requests\n",
    "\n",
    "import time\n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "scope = \"https://spreadsheets.google.com/feeds\"\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(\"matcher-272116-8801bce55bcb.json\", scope)\n",
    "gs = gspread.authorize(credentials)\n",
    "\n",
    "data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Journey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No journeys available\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.anyvan.com/board/cyfe/express_interest_expresses\"\n",
    "s = requests.get(url).content\n",
    "\n",
    "try :\n",
    "    data = pd.read_csv(io.StringIO(s.decode(\"utf-8\"))).sort_values(by = [\"start_end\"], ascending = False)\n",
    "except :\n",
    "    print(\"No journeys available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/1o7jEklbPYk-7So0UALnt8dZCYlIbdyXhzsgm9MHf82I/edit#gid=0\"\n",
    "\n",
    "express_guaranteed_sheet = gs.open_by_url(url).worksheet(\"journeys\").get_all_values()\n",
    "data = pd.DataFrame(express_guaranteed_sheet[1:], columns = express_guaranteed_sheet[0])\n",
    "data = data.replace(\"\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/1_syJVv1Uni8oSa9BhtAjVcl2EZYZmJn03VKg9vofcD4/edit#gid=0\"\n",
    "\n",
    "return_journey_converter_sheet = gs.open_by_url(url).worksheet(\"Input\").get_all_values()[15:]\n",
    "returns = pd.DataFrame(return_journey_converter_sheet[1:], columns = return_journey_converter_sheet[0])\n",
    "returns = returns.drop(columns = returns.columns[16:])\n",
    "returns[\"nickname\"].replace(\"\", float(\"NaN\"), inplace = True)\n",
    "returns = returns.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = {\"Luton Van\" : 20, \n",
    "         \"LWB up to 4m\" : 10.5,\n",
    "         \"MWB up to 3m\" : 7.5,\n",
    "         \"Not applicable\" : 12,\n",
    "         \"XLWB up 4m+\" : 14.5,\n",
    "         \"SWB up to 2.4m\" : 5.5,\n",
    "         \"Small Van\" : 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/1t0L9sgsUt-BT7wJWBNZ4fNY-Bo5GNytXP1wmkejFVw0/edit#gid=1205069010\"\n",
    "\n",
    "TP_log_providers_sheet = gs.open_by_url(url).worksheet(\"format2\").get_all_values()[7:]\n",
    "TP_log_providers = pd.DataFrame(TP_log_providers_sheet[1:], columns = TP_log_providers_sheet[0])\n",
    "providers = TP_log_providers.where(np.logical_and(TP_log_providers[\"vehicle\"] != \"N/A\", np.logical_and(TP_log_providers[\"TP & REG\"] != \"AVStore #YN19FHD\", np.logical_and(TP_log_providers[\"TP & REG\"] != \"1London #YN19FHF\", TP_log_providers[\"TP & REG\"] != \"DWB91 #YN19FHD\")))).dropna(how = \"all\").reset_index(drop = True).drop(columns = TP_log_providers.columns[-1])\n",
    "date = providers.columns[-1]\n",
    "\n",
    "providers[\"Size\"] = [sizes[vehicle] for vehicle in providers[\"vehicle\"]]\n",
    "providers[\"National?\"] = [int(math.ceil(55 + (100 - float(nuts2c)) / 2 + (2000 if code.endswith(\"N\") else 0))) for nuts2c,code in zip(providers[\"nuts2c\"], providers[date])]\n",
    "providers[\"1Man\"] = [1 if (code.startswith(\"1\") or code.startswith(\"O\")) else 0 for code in providers[date]]\n",
    "providers[\"2Man\"] = [2 if (code.startswith(\"2\") or code.startswith(\"O\")) else 0 for code in providers[date]]\n",
    "providers[\"returns\"] = [1 if TP in returns[\"name#reg\"] else 0 for TP in providers[\"TP & REG\"]]\n",
    "providers[\"guaranteed\"] = [1 if isreturn == 1 else -1 for isreturn in providers[\"returns\"]]\n",
    "providers[\"special code\"] = [\"2man-TL-LDN-cc\" if (TwoMan == 2 and TL == \"1\") else \"TL-LDN-cc\" if (TL == \"1\") else \"2man-LDN-cc\" if (TwoMan == 2) else \"LDN-cc\" for TwoMan,TL in zip(providers[\"2Man\"], providers[\"TL\"])]\n",
    "providers[\"capacity\"] = [16 if size >= 16 else size for size in providers[\"Size\"]]\n",
    "\n",
    "providers = providers.sort_values(by = [\"TP & REG\"]).reset_index(drop = True)\n",
    "providers[\"index\"] = providers.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expressing TPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"TP\", \"lat\", \"lng\", \"expressions\", \"guaranteed\", \"boooked\"]\n",
    "expressing_TPs = pd.DataFrame(columns = columns)\n",
    "\n",
    "if data is not None :\n",
    "    for TP in data[\"name#reg\"].dropna().unique() :\n",
    "        data_TP = data.where(data[\"name#reg\"] == TP).dropna(how = \"all\")\n",
    "        lat = round(float(data_TP.iloc[0][\"veh_lat\"]), 2)\n",
    "        lng = round(float(data_TP.iloc[0][\"veh_lng\"]), 2)\n",
    "        expressions = len(data_TP.index)\n",
    "        guaranteed = 1 if (TP in providers[\"TP & REG\"] or TP in returns[\"name#reg\"]) else 0\n",
    "        booked = 1 if TP in returns[\"name#reg\"] else 0\n",
    "        expressing_TPs = expressing_TPs.append(pd.DataFrame([[TP, lat, lng, expressions, guaranteed, booked]], columns = columns))\n",
    "else :\n",
    "    print(\"No journeys available\")\n",
    "    \n",
    "expressing_TPs = expressing_TPs.sort_values(by = [\"TP\"]).reset_index(drop = True)\n",
    "expressing_TPs[\"index\"] = expressing_TPs.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_namereg = np.append(providers[\"TP & REG\"], expressing_TPs[\"TP\"])\n",
    "TP_lat = np.append(providers[\"Lat\"], expressing_TPs[\"lat\"])\n",
    "TP_lng = np.append(providers[\"Lng\"], expressing_TPs[\"lng\"])\n",
    "TP_TL = np.append(providers[\"TL\"], np.full(len(expressing_TPs.index), np.nan))\n",
    "TP_capacity = np.append(providers[\"Size\"], np.full(len(expressing_TPs.index), np.nan))\n",
    "TP_maxkm = np.append(providers[\"National?\"], np.full(len(expressing_TPs.index), np.nan))\n",
    "TP_1man = np.append(providers[\"1Man\"], np.full(len(expressing_TPs.index), np.nan))\n",
    "TP_2man = np.append(providers[\"2Man\"], np.full(len(expressing_TPs.index), np.nan))\n",
    "TP_guaranteed = np.append(providers[\"guaranteed\"], expressing_TPs[\"guaranteed\"])\n",
    "TP_provider = np.append(np.ones(len(providers.index), dtype = bool), np.zeros(len(expressing_TPs.index), dtype = bool))\n",
    "\n",
    "columns = [\"TP\", \"lat\", \"lng\", \"TL\", \"capacity\", \"maxkm\", \"1man\", \"2man\", \"guaranteed\", \"provider\"]\n",
    "TPs = pd.DataFrame(zip(TP_namereg, TP_lat, TP_lng, TP_TL, TP_capacity, TP_maxkm, TP_1man, TP_2man, TP_guaranteed, TP_provider), columns = columns)\n",
    "TPs = TPs.where(TPs[\"guaranteed\"] <= 0).dropna(how = \"all\").sort_values(by = [\"provider\", \"TP\"], ascending = [False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate iarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_funct(start_lat, start_lng, lat, lng) :\n",
    "    return 2 * 6371 * np.arcsin(np.sqrt(np.sin((start_lat - lat) * np.pi / 360) ** 2 \n",
    "                                           + np.cos(start_lat * np.pi / 180) \n",
    "                                           * np.cos(lat * np.pi / 180) \n",
    "                                           * np.sin((start_lng - lng) * np.pi / 360) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 1.930 secs to run\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if data is not None :\n",
    "    journeys = data[\"journey_id\"].unique()\n",
    "    iarray = np.zeros((len(TPs.index), len(journeys)), dtype = float)\n",
    "\n",
    "    for i in range(len(journeys)) :\n",
    "        journey = data.where(data[\"journey_id\"] == journeys[i]).dropna(how = \"all\")\n",
    "        \n",
    "        for j in range(len(TPs.index)) :\n",
    "            if int(TPs[\"guaranteed\"].iloc[j]) == -1 :\n",
    "                if TPs[\"TP\"].iloc[j] in journey[\"name#reg\"].values :\n",
    "                    journey_subset = journey.where(journey[\"name#reg\"] == TPs[\"TP\"].iloc[j]).dropna(how = \"all\").iloc[0]\n",
    "                    if float(journey_subset[\"min_dist\"]) >= 5 :\n",
    "                        iarray[j, i] = 5\n",
    "                    else :\n",
    "                        iarray[j, i] = float(journey_subset[\"min_dist\"])\n",
    "                else :\n",
    "                    if float(journey[\"max_m3\"].iloc[0]) <= float(TPs[\"capacity\"].iloc[j]) :\n",
    "                        if float(journey[\"start_end\"].iloc[0]) <= float(TPs[\"maxkm\"].iloc[j]) :\n",
    "                            if int(journey[\"number_of_men\"].iloc[0]) == int(TPs[\"1man\"].iloc[j]) or int(journey[\"number_of_men\"].iloc[0]) == int(TPs[\"2man\"].iloc[j]) :\n",
    "                                if int(journey[\"tail_lift\"].iloc[0]) <= int(TPs[\"TL\"].iloc[j]) :\n",
    "                                    distance = distance_funct(float(journey[\"start_lat\"].iloc[0]), float(journey[\"start_lng\"].iloc[0]), float(TPs[\"lat\"].iloc[j]), float(TPs[\"lng\"].iloc[j]))\n",
    "                                    if distance <= (float(TPs[\"maxkm\"].iloc[j]) if float(TPs[\"maxkm\"].iloc[j]) < 2000 else float(TPs[\"maxkm\"].iloc[j]) - 2000) :\n",
    "                                        iarray[j, i] = distance\n",
    "            elif TPs[\"TP\"].iloc[j] in journey[\"name#reg\"].values :\n",
    "                iarray[j, i] = float(journey.where(journey[\"name#reg\"] == TPs[\"TP\"].iloc[j]).dropna(how = \"all\")[\"min_dist\"].iloc[0])\n",
    "else :\n",
    "    print(\"No journeys available\")\n",
    "                \n",
    "print(\"Took {0:.3f} secs to run\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A1Van #FD61BLV', 0.0),\n",
       " ('Abeysaab #YD66NXM', 0.0),\n",
       " ('AntTrans #LR67KTU', 15.393330421768995),\n",
       " ('Apcybul #GJ15JVM', 26.052854440188657),\n",
       " ('BARTHA85 #KW14VFL', 0.0),\n",
       " ('BrockRem #CP09UFS', 0.0),\n",
       " ('BuzzBogn #TS54BUZ', 0.0),\n",
       " ('CODE2019 #YG61LRK', 0.0),\n",
       " ('Cieslik8 #CE17ZZF', 0.0),\n",
       " ('Core2012 #GN06PPZ', 28.56693185021415),\n",
       " ('Crisrey1 #KV59VGM', 9.59429253539582),\n",
       " ('DJB #FD17JBV', 0.0),\n",
       " ('DWB911 #YM66HRP', 2.72),\n",
       " ('DannyB17 #LJ15VHL', 0.0),\n",
       " ('Dapitan7 #688KM', 0.0),\n",
       " ('Davies56 #RV08OOY', 0.0),\n",
       " ('DawPol #YE16UCL', 0.0),\n",
       " ('Dprroni #KM69HLA', 0.0),\n",
       " ('ERmove #MO09VER', 0.0),\n",
       " ('GMS2019 #LC57KVA', 29.163850686319517),\n",
       " ('Gaben456 #MK16OHU', 0.0),\n",
       " ('Gelmoves #CA69YLB', 23.521770042517787),\n",
       " ('Gsavas #KN60YOR', 0.0),\n",
       " ('Indulis #MW56NGJ', 0.0),\n",
       " ('ItemDrop #DO03DOE', 0.0),\n",
       " ('JSJMOVE #KU62FFM', 0.0),\n",
       " ('Kamelia7 #BW65PXC', 0.0),\n",
       " ('Kevvan #DU16FFJ', 18.298029952402274),\n",
       " ('LCS2019 #BK11VBZ11', 0.0),\n",
       " ('Ltgibb5 #CN67DYF', 0.0),\n",
       " ('Mal2020 #DE59KZY', 0.0),\n",
       " ('Maps85 #HG59FDU', 0.0),\n",
       " ('Marek234 #KV04CPX', 39.509547475649356),\n",
       " ('Mary2407 #WX16OMO', 0.0),\n",
       " ('Mihaiins #EJ59JJX', 0.0),\n",
       " ('Movedeco #KV09EVV', 17.844781747765502),\n",
       " ('Moveu1 #FX57WNO', 12.250965757381143),\n",
       " ('Nek83 #SG12HPN', 8.668135107657287),\n",
       " ('Olajide2 #GJ06URC', 0.0),\n",
       " ('P2106 #AV66UTN', 0.0),\n",
       " ('Pmtltd #NX15BFM', 10.127420445106827),\n",
       " ('Power77 #KS08VAX', 16.93915003901613),\n",
       " ('Priory01 #KU16GXE', 0.0),\n",
       " ('Rema16 #EX69LZS', 0.0),\n",
       " ('RossW83 #KM13ZKA', 0.0),\n",
       " ('SDremove #BJ15HZH1', 0.0),\n",
       " ('TFDutch #KP60DHG', 0.0),\n",
       " ('VanEDI #HK16XUY', 0.0),\n",
       " ('Vitalco #KS04UKE', 44.68709378896685),\n",
       " ('Vitalco #KU14LSX', 44.68709378896685),\n",
       " ('Waliza #YN68FOA', 36.00779209999099),\n",
       " ('Zapoman #EO68CNN', 0.0),\n",
       " ('A1Van #FD61BLV', 0.0),\n",
       " ('ADEKOL1 #ND63EXZ', 0.0),\n",
       " ('ARGmoves #GC18GYY', 12.64),\n",
       " ('Abeysaab #YD66NXM', 0.0),\n",
       " ('BARTHA85 #KW14VFL', 0.0),\n",
       " ('BenOne #HJ57RWE', 0.0),\n",
       " ('Beni123 #RY07YVO', 0.0),\n",
       " ('Bogdan18 #GM18UDN', 0.0),\n",
       " ('Boison #DA63FZS', 0.0),\n",
       " ('Buck2012 #FG60AVK', 0.0),\n",
       " ('CODE2019 #YG61LRK', 0.0),\n",
       " ('Cieslik8 #CE17ZZF', 0.0),\n",
       " ('Clarky16 #KV64DHZ', 0.0),\n",
       " ('Clarky16 #KX65UFP', 0.0),\n",
       " ('Cos1984 #NX65DEU', 0.0),\n",
       " ('Crawle81 #KX67KXB', 0.0),\n",
       " ('Cushy44 #YB62RMZ', 0.0),\n",
       " ('DISped #MW60DXB', 0.0),\n",
       " ('DW5 #KE07BLF', 0.0),\n",
       " ('DWB911 #YM66HRP', 0.0),\n",
       " ('DannyB17 #YG61KWX', 0.0),\n",
       " ('DawPol #YE16UCL', 0.0),\n",
       " ('Dultsev #GK67YYO', 0.0),\n",
       " ('Dultsev #WR11EKW', 0.0),\n",
       " ('ELABA #KT15MXZ', 0.0),\n",
       " ('ElmTrans #CCA686M1', 0.0),\n",
       " ('Emmani #EX12OCM', 8.81),\n",
       " ('Euorders #KR08KWK', 0.0),\n",
       " ('EuroXL #BF65FXP', 0.0),\n",
       " ('Fisani #DK62XCC', 0.0),\n",
       " ('Ford13 #KP62NUE', 0.0),\n",
       " ('GMS2019 #BG61ECY', 28.83),\n",
       " ('Gsavas #KN60YOR', 0.0),\n",
       " ('Gurbonas #ND61SVP', 0.0),\n",
       " ('Haul4u #WM14B2B', 0.0),\n",
       " ('Hris88 #BF57PXW', 27.06),\n",
       " ('Hulklogi #BJ15FCV', 0.0),\n",
       " ('Hulklogi #RE63WYG', 0.0),\n",
       " ('IuliusN #MF12UEK', 0.0),\n",
       " ('JSJMOVE #KU62FFM', 0.0),\n",
       " ('Jasza82 #HX66DAO', 0.0),\n",
       " ('Jhobman1 #YJ63ORG', 0.0),\n",
       " ('Jlmhaul1 #YK65YSJ', 0.0),\n",
       " ('Jojoacti #LM67OXG', 0.0),\n",
       " ('KWGSCasa #MV65DZP', 0.0),\n",
       " ('Karlfred #0Y16GBF', 0.0),\n",
       " ('Kianna5 #SJ13JZA', 0.0),\n",
       " ('LCS2019 #BK11VBZ11', 0.0),\n",
       " ('Levaetra #J90ABY', 0.0),\n",
       " ('Light019 #KY14ODR', 0.0),\n",
       " ('MBalan #LC65CUK', 0.0),\n",
       " ('Majdmota #GFZ4532', 0.0),\n",
       " ('Mal2020 #DE59KZY', 0.0),\n",
       " ('Mariuskm #BG15NUE', 0.0),\n",
       " ('Markbxxx #LA69FFT', 0.0),\n",
       " ('Mary2407 #WX16OMO', 0.0),\n",
       " ('Mcmtport #LT08DMO', 0.0),\n",
       " ('MerchD1 #PN63NXL1', 0.0),\n",
       " ('Mickeyr #OU62HDK', 0.0),\n",
       " ('Milana2b #PL03WCC', 0.0),\n",
       " ('Milesuk #SF08FLH', 0.0),\n",
       " ('Mosaq13 #KW07XUJ', 0.0),\n",
       " ('Movedeco #KP57URY', 0.0),\n",
       " ('NRemova5 #AK15YVZ', 0.0),\n",
       " ('Ndubuaku #YL08JZX', 0.0),\n",
       " ('Ngup2020 #CU57EXM1', 0.0),\n",
       " ('Pencho84 #FL57VXG', 9.21),\n",
       " ('Power77 #DU07TLK', 0.0),\n",
       " ('Prada7 #KN62DMY', 0.0),\n",
       " ('RMDTrans #FH12YVG', 0.0),\n",
       " ('SDremove #BJ15HZH1', 0.0),\n",
       " ('ShiningH #EN59PZK', 0.0),\n",
       " ('Stuieh #NX64ATN', 0.0),\n",
       " ('Swmanvan #OU60ZHJ', 0.0),\n",
       " ('Vanacy01 #DT18LPC', 0.0),\n",
       " ('Vilmresa #SG61NPC', 0.0),\n",
       " ('Vitalco #KS04UKE', 0.0),\n",
       " ('Vitalco #KU14LSX', 0.0)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(TPs[\"TP\"],iarray.transpose()[np.argwhere(journeys == \"33238\")[0][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
